
## Links to External Notes
https://docs.google.com/document/d/1p3zQzrduVzZkk2SYbNfdtBJpcRvlLWnqjji5JNzQHME/edit?usp=sharing


## Tasks

@BeanHam
Can we use RGB (or grayscale) encoded images, represented as text, as input to an LLM to do non-trivial classification tasks?
i.e., take an MNIST image, print the sequence of grayscale values as text, and provide it in a prompt to an LLM with the question "What is this a picture of?"
If this works, it's feasible to do simple image work, inefficiently, using text-only models.

@isaacOnline
How good is ChatpGPT4 on the [hiring task](https://www.microsoft.com/en-us/download/details.aspx?id=105296) with zero and few-shot learning?

@evamaxfield
How hard is it to get a llama fine-tuning pipeline (with [qlora](https://github.com/artidoro/qlora)) on EC2 using reasonable resources?

@bernease and @light-and-salt
Can we get a lab website established with Hugo in the website [repo](https://github.com/BillHoweLab/website)?




