# Open Model Text Summarization

## Questions

Is Mistral competitive with GPT-4 on Text Summarization?
What role does the lack of RLHF play?
If not, can fine-tuning achieve competitive results?

## Description

Attend to [Heilmeier's catechism](https://www.darpa.mil/work-with-us/heilmeier-catechism).

We want to understand the performance gap on text summarization between opaque LLMs and open models.  These results will inform a recipe for specialized text processing tasks in .gov contexts.

## Design

- Use the XYZ dataset <link to data>
- Use the MistralV123 model <link to code>
- Modify the data
- Train like this....

## Results

images were appropriate
